{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0c5c88",
   "metadata": {},
   "source": [
    "# Амангелді Нұрғалым - Зертханалық жұмыс, СИБ 23-01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0525d76",
   "metadata": {},
   "source": [
    "## Импортируем необходимые библиотеки для создания генеративно-состязательной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74eccaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import time  # Для работы с временем\n",
    "import torch  # Основная библиотека PyTorch\n",
    "import torch.nn as nn  # Модуль нейронных сетей PyTorch\n",
    "import torch.optim as optim  # Оптимизаторы PyTorch\n",
    "from torch.utils.data import DataLoader  # Загрузчик данных PyTorch\n",
    "from torchvision import datasets  # Датасеты для компьютерного зрения PyTorch\n",
    "from torchvision.transforms import transforms  # Преобразования изображений PyTorch\n",
    "#from model import discriminator, generator #\n",
    "import numpy as np  # Библиотека для работы с массивами данных\n",
    "import matplotlib.pyplot as plt  # Библиотека для визуализации данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110433da",
   "metadata": {},
   "source": [
    "## Определяем, доступны ли какие-либо графические процессоры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14eb772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем устройство, на котором будет выполняться вычисления (GPU, если доступен, иначе CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14f281",
   "metadata": {},
   "source": [
    "## Сетевые архитектуры\n",
    "## Ниже приведены архитектуры дискриминатора и генератора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7150df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение класса дискриминатора\n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        # Первый полносвязный слой с 784 входами и 512 выходами\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        # Второй полносвязный слой с 512 входами и 1 выходом\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        # Функция активации LeakyReLU с коэффициентом наклона 0.1\n",
    "        self.activation = nn.LeakyReLU(0.1)\n",
    "\n",
    "    # Метод forward, определяющий проход вперед через сеть\n",
    "    def forward(self, x):\n",
    "        # При изменении формы тензора учтем размер батча и количество признаков\n",
    "        x = x.view(-1, 784)\n",
    "        # Применение активации к первому слою\n",
    "        x = self.activation(self.fc1(x))\n",
    "        # Применение второго слоя\n",
    "        x = self.fc2(x)\n",
    "        # Применение сигмоидной функции для получения вероятности\n",
    "        return nn.Sigmoid()(x)\n",
    "\n",
    "# Определение класса генератора\n",
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        # Первый полносвязный слой с 128 входами и 1024 выходами\n",
    "        self.fc1 = nn.Linear(128, 1024)\n",
    "        # Второй полносвязный слой с 1024 входами и 2048 выходами\n",
    "        self.fc2 = nn.Linear(1024, 2048)\n",
    "        # Третий полносвязный слой с 2048 входами и 784 выходами\n",
    "        self.fc3 = nn.Linear(2048, 784)\n",
    "        # Функция активации ReLU\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    # Метод forward, определяющий проход вперед через сеть\n",
    "    def forward(self, x):\n",
    "        # Применение активации к первому слою\n",
    "        x = self.activation(self.fc1(x))\n",
    "        # Применение активации ко второму слою\n",
    "        x = self.activation(self.fc2(x))\n",
    "        # Применение третьего слоя\n",
    "        x = self.fc3(x)\n",
    "        # Изменение формы тензора, чтобы получить изображение 28x28\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        # Применение гиперболического тангенса к выходу\n",
    "        return nn.Tanh()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aabe312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение функции потерь для дискриминатора\n",
    "# Используется бинарная кросс-энтропия (BCELoss)\n",
    "def d_loss_function(inputs, targets):\n",
    "    return nn.BCELoss()(inputs, targets)\n",
    "\n",
    "# Определение функции потерь для генератора\n",
    "# Целевые метки для генератора - единицы (ожидаем, чтобы дискриминатор принимал сгенерированные изображения)\n",
    "def g_loss_function(inputs):\n",
    "    # Создание тензора целевых меток состоящего из единиц\n",
    "    targets = torch.ones([inputs.shape[0], 1])\n",
    "    targets = targets.to(device)\n",
    "    # Используется бинарная кросс-энтропия (BCELoss)\n",
    "    return nn.BCELoss()(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e62451b",
   "metadata": {},
   "source": [
    "## Определяем, доступны ли какие-либо графические процессоры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d122b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU State: cpu\n",
      "generator(\n",
      "  (fc1): Linear(in_features=128, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "  (fc3): Linear(in_features=2048, out_features=784, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n",
      "discriminator(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (activation): LeakyReLU(negative_slope=0.1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU State:', device)\n",
    "\n",
    "# Model\n",
    "G = generator().to(device)\n",
    "D = discriminator().to(device)\n",
    "print(G)\n",
    "print(D)\n",
    "\n",
    "# Settings\n",
    "epochs = 10\n",
    "lr = 0.0002\n",
    "batch_size = 64\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "\n",
    "# Load data\n",
    "train_set = datasets.MNIST('mnist/', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST('mnist/', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973eb58d",
   "metadata": {},
   "source": [
    "### Процедура обучения сети.\n",
    "### Этот код представляет собой цикл обучения для генеративно-состязательной сети (GAN). Дискриминатор и генератор обучаются поочередно, а затем сохраняется модель генератора после каждых 10 эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf79264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Iteration 100: discriminator_loss 0.595 generator_loss 0.987\n",
      "Epoch 0 Iteration 200: discriminator_loss 0.636 generator_loss 0.775\n",
      "Epoch 0 Iteration 300: discriminator_loss 0.607 generator_loss 0.826\n",
      "Epoch 0 Iteration 400: discriminator_loss 0.660 generator_loss 0.806\n",
      "Epoch 0 Iteration 500: discriminator_loss 0.630 generator_loss 0.798\n",
      "Epoch 0 Iteration 600: discriminator_loss 0.571 generator_loss 0.814\n",
      "Epoch 0 Iteration 700: discriminator_loss 0.482 generator_loss 0.923\n",
      "Epoch 0 Iteration 800: discriminator_loss 0.482 generator_loss 0.925\n",
      "Epoch 0 Iteration 900: discriminator_loss 0.460 generator_loss 1.143\n",
      "Epoch 0 Iteration 938: discriminator_loss 0.486 generator_loss 1.135\n",
      "Epoch 1 Iteration 100: discriminator_loss 0.485 generator_loss 1.209\n",
      "Epoch 1 Iteration 200: discriminator_loss 0.466 generator_loss 1.248\n",
      "Epoch 1 Iteration 300: discriminator_loss 0.398 generator_loss 1.589\n",
      "Epoch 1 Iteration 400: discriminator_loss 0.402 generator_loss 1.434\n",
      "Epoch 1 Iteration 500: discriminator_loss 0.425 generator_loss 1.706\n",
      "Epoch 1 Iteration 600: discriminator_loss 0.552 generator_loss 1.477\n",
      "Epoch 1 Iteration 700: discriminator_loss 0.401 generator_loss 1.760\n",
      "Epoch 1 Iteration 800: discriminator_loss 0.426 generator_loss 1.584\n",
      "Epoch 1 Iteration 900: discriminator_loss 0.448 generator_loss 1.183\n",
      "Epoch 1 Iteration 938: discriminator_loss 0.369 generator_loss 1.371\n",
      "Epoch 2 Iteration 100: discriminator_loss 0.443 generator_loss 1.450\n",
      "Epoch 2 Iteration 200: discriminator_loss 0.527 generator_loss 1.184\n",
      "Epoch 2 Iteration 300: discriminator_loss 0.509 generator_loss 1.391\n",
      "Epoch 2 Iteration 400: discriminator_loss 0.520 generator_loss 1.808\n",
      "Epoch 2 Iteration 500: discriminator_loss 0.644 generator_loss 1.440\n",
      "Epoch 2 Iteration 600: discriminator_loss 0.540 generator_loss 1.194\n",
      "Epoch 2 Iteration 700: discriminator_loss 0.527 generator_loss 1.547\n",
      "Epoch 2 Iteration 800: discriminator_loss 0.539 generator_loss 1.228\n",
      "Epoch 2 Iteration 900: discriminator_loss 0.532 generator_loss 1.191\n",
      "Epoch 2 Iteration 938: discriminator_loss 0.484 generator_loss 1.454\n",
      "Epoch 3 Iteration 100: discriminator_loss 0.472 generator_loss 1.288\n",
      "Epoch 3 Iteration 200: discriminator_loss 0.550 generator_loss 1.436\n",
      "Epoch 3 Iteration 300: discriminator_loss 0.565 generator_loss 1.765\n",
      "Epoch 3 Iteration 400: discriminator_loss 0.491 generator_loss 1.185\n",
      "Epoch 3 Iteration 500: discriminator_loss 0.561 generator_loss 1.580\n",
      "Epoch 3 Iteration 600: discriminator_loss 0.619 generator_loss 1.011\n",
      "Epoch 3 Iteration 700: discriminator_loss 0.555 generator_loss 1.194\n",
      "Epoch 3 Iteration 800: discriminator_loss 0.537 generator_loss 1.209\n",
      "Epoch 3 Iteration 900: discriminator_loss 0.533 generator_loss 1.133\n",
      "Epoch 3 Iteration 938: discriminator_loss 0.486 generator_loss 1.251\n",
      "Epoch 4 Iteration 100: discriminator_loss 0.516 generator_loss 1.216\n",
      "Epoch 4 Iteration 200: discriminator_loss 0.587 generator_loss 1.076\n",
      "Epoch 4 Iteration 300: discriminator_loss 0.630 generator_loss 0.940\n",
      "Epoch 4 Iteration 400: discriminator_loss 0.524 generator_loss 1.306\n",
      "Epoch 4 Iteration 500: discriminator_loss 0.534 generator_loss 1.359\n",
      "Epoch 4 Iteration 600: discriminator_loss 0.531 generator_loss 1.190\n",
      "Epoch 4 Iteration 700: discriminator_loss 0.525 generator_loss 1.355\n",
      "Epoch 4 Iteration 800: discriminator_loss 0.523 generator_loss 1.486\n",
      "Epoch 4 Iteration 900: discriminator_loss 0.528 generator_loss 1.199\n",
      "Epoch 4 Iteration 938: discriminator_loss 0.684 generator_loss 0.537\n",
      "Epoch 5 Iteration 100: discriminator_loss 0.539 generator_loss 1.281\n",
      "Epoch 5 Iteration 200: discriminator_loss 0.537 generator_loss 0.889\n",
      "Epoch 5 Iteration 300: discriminator_loss 0.653 generator_loss 1.587\n",
      "Epoch 5 Iteration 400: discriminator_loss 0.522 generator_loss 1.146\n",
      "Epoch 5 Iteration 500: discriminator_loss 0.484 generator_loss 1.080\n",
      "Epoch 5 Iteration 600: discriminator_loss 0.570 generator_loss 1.272\n",
      "Epoch 5 Iteration 700: discriminator_loss 0.590 generator_loss 1.136\n",
      "Epoch 5 Iteration 800: discriminator_loss 0.652 generator_loss 0.841\n",
      "Epoch 5 Iteration 900: discriminator_loss 0.640 generator_loss 1.499\n",
      "Epoch 5 Iteration 938: discriminator_loss 0.561 generator_loss 1.132\n",
      "Epoch 6 Iteration 100: discriminator_loss 0.574 generator_loss 1.051\n",
      "Epoch 6 Iteration 200: discriminator_loss 0.730 generator_loss 1.502\n",
      "Epoch 6 Iteration 300: discriminator_loss 0.622 generator_loss 1.507\n",
      "Epoch 6 Iteration 400: discriminator_loss 0.544 generator_loss 1.031\n",
      "Epoch 6 Iteration 500: discriminator_loss 0.606 generator_loss 1.077\n",
      "Epoch 6 Iteration 600: discriminator_loss 0.572 generator_loss 1.197\n",
      "Epoch 6 Iteration 700: discriminator_loss 0.562 generator_loss 1.015\n",
      "Epoch 6 Iteration 800: discriminator_loss 0.585 generator_loss 0.837\n",
      "Epoch 6 Iteration 900: discriminator_loss 0.727 generator_loss 0.980\n",
      "Epoch 6 Iteration 938: discriminator_loss 0.638 generator_loss 0.639\n",
      "Epoch 7 Iteration 100: discriminator_loss 0.608 generator_loss 0.858\n",
      "Epoch 7 Iteration 200: discriminator_loss 0.523 generator_loss 0.815\n",
      "Epoch 7 Iteration 300: discriminator_loss 0.598 generator_loss 0.778\n",
      "Epoch 7 Iteration 400: discriminator_loss 0.672 generator_loss 0.697\n",
      "Epoch 7 Iteration 500: discriminator_loss 0.622 generator_loss 1.168\n",
      "Epoch 7 Iteration 600: discriminator_loss 0.617 generator_loss 0.940\n",
      "Epoch 7 Iteration 700: discriminator_loss 0.650 generator_loss 1.335\n",
      "Epoch 7 Iteration 800: discriminator_loss 0.656 generator_loss 0.949\n",
      "Epoch 7 Iteration 900: discriminator_loss 0.674 generator_loss 1.082\n",
      "Epoch 7 Iteration 938: discriminator_loss 0.615 generator_loss 1.210\n",
      "Epoch 8 Iteration 100: discriminator_loss 0.666 generator_loss 0.615\n",
      "Epoch 8 Iteration 200: discriminator_loss 0.645 generator_loss 0.915\n",
      "Epoch 8 Iteration 300: discriminator_loss 0.641 generator_loss 0.856\n",
      "Epoch 8 Iteration 400: discriminator_loss 0.633 generator_loss 1.124\n",
      "Epoch 8 Iteration 500: discriminator_loss 0.616 generator_loss 0.937\n",
      "Epoch 8 Iteration 600: discriminator_loss 0.624 generator_loss 0.858\n",
      "Epoch 8 Iteration 700: discriminator_loss 0.609 generator_loss 1.163\n",
      "Epoch 8 Iteration 800: discriminator_loss 0.609 generator_loss 0.640\n",
      "Epoch 8 Iteration 900: discriminator_loss 0.643 generator_loss 0.869\n",
      "Epoch 8 Iteration 938: discriminator_loss 0.590 generator_loss 0.992\n",
      "Epoch 9 Iteration 100: discriminator_loss 0.644 generator_loss 1.144\n",
      "Epoch 9 Iteration 200: discriminator_loss 0.634 generator_loss 0.711\n",
      "Epoch 9 Iteration 300: discriminator_loss 0.636 generator_loss 0.841\n",
      "Epoch 9 Iteration 400: discriminator_loss 0.593 generator_loss 0.760\n",
      "Epoch 9 Iteration 500: discriminator_loss 0.625 generator_loss 0.736\n",
      "Epoch 9 Iteration 600: discriminator_loss 0.663 generator_loss 1.031\n",
      "Epoch 9 Iteration 700: discriminator_loss 0.620 generator_loss 1.151\n",
      "Epoch 9 Iteration 800: discriminator_loss 0.656 generator_loss 1.209\n",
      "Epoch 9 Iteration 900: discriminator_loss 0.604 generator_loss 0.699\n",
      "Epoch 9 Iteration 938: discriminator_loss 0.627 generator_loss 0.918\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for idx, (imgs, _) in enumerate(train_loader):\n",
    "        idx += 1\n",
    "        # Обучение дискриминатора\n",
    "        # real_inputs - изображения из набора данных MNIST\n",
    "        # fake_inputs - изображения от генератора\n",
    "        # real_inputs должны быть классифицированы как 1, а fake_inputs - как 0\n",
    "        real_inputs = imgs.to(device)\n",
    "        real_outputs = D(real_inputs)\n",
    "        real_label = torch.ones(real_inputs.shape[0], 1).to(device)\n",
    "        noise = (torch.rand(real_inputs.shape[0], 128) - 0.5) / 0.5\n",
    "        noise = noise.to(device)\n",
    "        fake_inputs = G(noise)\n",
    "        fake_outputs = D(fake_inputs)\n",
    "        fake_label = torch.zeros(fake_inputs.shape[0], 1).to(device)\n",
    "        outputs = torch.cat((real_outputs, fake_outputs), 0)\n",
    "        targets = torch.cat((real_label, fake_label), 0)\n",
    "        d_loss = d_loss_function(outputs, targets)\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # Обучение генератора\n",
    "        # Цель генератора получить от дискриминатора 1 по всем изображениям\n",
    "        noise = (torch.rand(real_inputs.shape[0], 128) - 0.5) / 0.5\n",
    "        noise = noise.to(device)\n",
    "        fake_inputs = G(noise)\n",
    "        fake_outputs = D(fake_inputs)\n",
    "        fake_targets = torch.ones([fake_inputs.shape[0], 1]).to(device)\n",
    "        g_loss = g_loss_function(fake_outputs)\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        # Вывод информации о потерях на каждой итерации\n",
    "        if idx % 100 == 0 or idx == len(train_loader):\n",
    "            print('Epoch {} Iteration {}: discriminator_loss {:.3f} generator_loss {:.3f}'.format(epoch, idx, d_loss.item(), g_loss.item()))\n",
    "    \n",
    "    # Сохранение модели генератора каждые 10 эпох\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(G, 'Generator_epoch_{}.pth'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66835dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "print('Model saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c001bc50",
   "metadata": {},
   "source": [
    "### После 10 эпох мы можем построить наборы данных и увидеть результаты — цифры сгенерированные из случайных шумов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75812c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
